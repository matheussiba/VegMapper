{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Hz7psgMiXU5w"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NaiaraSPinto/VegMapper/blob/master/gedi/gedi_l2a_arset.ipynb)\n"
      ],
      "metadata": {
        "id": "7TwP0_Z-ZGyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Install packages and import dependencies\n",
        "Sets up the environment by installing and importing the required Python libraries. This includes packages for interacting with NASA data services (`earthaccess`, `harmony-py`) and for general data handling and processing."
      ],
      "metadata": {
        "id": "KtlyJGDb9x6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4oHmHuihrNJb"
      },
      "outputs": [],
      "source": [
        "!pip install -q geoviews earthaccess harmony-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from harmony import BBox, Client, Collection, Request, CapabilitiesRequest\n",
        "from datetime import datetime\n",
        "import json\n",
        "import earthaccess\n",
        "import geopandas as gp\n",
        "import os\n",
        "from IPython.display import JSON\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "import ast\n",
        "import subprocess\n",
        "import requests\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "M2b0JhrdrlXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Authenticate with your NASA Earth Data credentials\n",
        "\n",
        "If you don't have an account, you can [register on the Earthdata website](https://urs.earthdata.nasa.gov/)."
      ],
      "metadata": {
        "id": "3wne6rqz96OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth = earthaccess.login(persist=True)"
      ],
      "metadata": {
        "id": "n5QYdolgrqOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Define AOI & Output Folder\n",
        "\n",
        "* Provide the path to a **GeoJSON file** to define your study area.\n",
        "* Specify the **output folder** where your results will be saved."
      ],
      "metadata": {
        "id": "4-wJmtMK-YMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_site = input(\"Enter the path to your GeoJSON polygon file: \")\n",
        "\n",
        "try:\n",
        "    with open(my_site) as f:\n",
        "        geojson_polygon = json.load(f)\n",
        "    print(\"GeoJSON loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {my_site}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Invalid GeoJSON format in file: {my_site}\")\n",
        "\n",
        "output_folder = input(\"Enter the output folder where you wish to save your results:\")"
      ],
      "metadata": {
        "id": "mq8S_rX7-it_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Define the temporal range of your search\n",
        "GEDI data availability:\n",
        "*   April 2019 - March 2023\n",
        "*   April 2024 - Present\n"
      ],
      "metadata": {
        "id": "ZqQWeK_vSgrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_str = input(\"Enter start date (YYYY-MM-DD): \")\n",
        "stop_str = input(\"Enter stop date (YYYY-MM-DD): \")\n",
        "\n",
        "# Convert input strings to datetime objects\n",
        "try:\n",
        "    temporal_range = {\n",
        "        'start': datetime.strptime(start_str, \"%Y-%m-%d\"),\n",
        "        'stop': datetime.strptime(stop_str, \"%Y-%m-%d\")\n",
        "    }\n",
        "    print(\"Temporal range set to:\", temporal_range)\n",
        "except ValueError:\n",
        "    print(\"Invalid date format. Please use YYYY-MM-DD.\")"
      ],
      "metadata": {
        "id": "a6P-27_PSaHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- Call the Harmony Service to subset GEDI granules\n",
        "Submits a request to the Harmony API for server-side subsetting of the GEDI L2A collection based on the specified AOI and time range."
      ],
      "metadata": {
        "id": "HT_B--Hb-oAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "harmony_client = Client(auth=(auth.username, auth.password))\n",
        "capabilities_request = CapabilitiesRequest(short_name='GEDI02_A')\n",
        "capabilities = harmony_client.submit(capabilities_request)\n",
        "concept_id = capabilities['conceptId']\n",
        "\n",
        "request = Request(\n",
        "    collection = Collection(id=concept_id),\n",
        "    shape = my_site,\n",
        "    temporal = temporal_range\n",
        ")\n",
        "task = harmony_client.submit(request)\n",
        "print(f'Harmony request ID: {task}')\n",
        "print(f'Processing your Harmony request:')\n",
        "task_json = harmony_client.result_json(task, show_progress=True)"
      ],
      "metadata": {
        "id": "V8oEfy2e-MbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6- Save URLs of subsetted granules\n",
        "This step saves a list that contains the remote location of files containing GEDI shots in H5 format. Here, we are only retrieving a list of file locations (URLs), not the files themselves."
      ],
      "metadata": {
        "id": "foioz9Ak-xHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h5_files = [link['href'] for link in task_json['links'] if link['href'].endswith('.h5')]\n",
        "h5_file_name = 'h5_files.txt'\n",
        "with open(os.path.join(output_folder, h5_file_name), 'w') as f:\n",
        "    for h5_file in h5_files:\n",
        "        f.write(h5_file + '\\n')\n",
        "\n",
        "print(f\"H5 file links saved to {h5_file_name}\")"
      ],
      "metadata": {
        "id": "CxquWYx27qQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7- Define Data Quality Filters\n",
        "Here are some commonly-used criteria:\n",
        "*   **Sensitivity** is the the maximum canopy cover through which the LiDAR can detect the ground with 90% probability, and it is useful in areas of **dense vegetation**\n",
        "*   **Min RH95** can be used to **exclude bare ground**\n",
        "*   **Night Time Shots** can be selected to maximize **signal-to-noise ratio**"
      ],
      "metadata": {
        "id": "Hz7psgMiXU5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sensitivity\n",
        "while True:\n",
        "    min_sens_input = input(\"Enter minimum sensitivity value (0.0-0.9): \")\n",
        "    try:\n",
        "        min_sens = float(min_sens_input)\n",
        "        # Check if the float is within the desired range\n",
        "        if 0.0 <= min_sens <= 0.9:\n",
        "            print(f\"Minimum sensitivity set to: {min_sens}\")\n",
        "            break  # Exit the loop if input is valid\n",
        "        else:\n",
        "            print(\"Error: The value must be between 0.0 and 0.9.\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Invalid input. Please enter a numerical value.\")\n",
        "\n",
        "#min RH95\n",
        "while True:\n",
        "    min_height_input = input(\"Enter minimum RH95 value (0-5): \")\n",
        "    try:\n",
        "        min_height = int(min_height_input)\n",
        "        # Check if the integer is within the desired range\n",
        "        if 0 <= min_height <= 5:\n",
        "            print(f\"Minimum height set to: {min_height}\")\n",
        "            break # Exit the loop if input is valid\n",
        "        else:\n",
        "            print(\"Error: The value must be between 0 and 5.\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Invalid input. Please enter a numerical value.\")\n",
        "\n",
        "#night time only\n",
        "try:\n",
        "    night_only = ast.literal_eval(input(\"Enter True or False for night only filtering: \"))\n",
        "    if isinstance(night_only, bool):\n",
        "        print(f\"The boolean value is: {night_only}\")\n",
        "    else:\n",
        "        print(\"Invalid input. The input must be 'True' or 'False'.\")\n",
        "except (ValueError, SyntaxError):\n",
        "    print(\"Invalid input. The input must be 'True' or 'False'.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TrShJcjTXUHO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8- Function to filter GEDI L2A shots\n",
        "For each H5 file, download from the DAAC, apply the user-specified filtering, and save results as a local CSV."
      ],
      "metadata": {
        "id": "oZVHb6FDyZEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the main function\n",
        "def extract_gedi_rh_metrics_from_urls(file_list_txt, csv_file, beams=None,\n",
        "                                      min_sensitivity=0.9, min_rh95=0,\n",
        "                                      night=False):\n",
        "    \"\"\"\n",
        "    Reads a list of HTTPS GEDI HDF5 file URLs, downloads each file completely,\n",
        "    extracts RH metrics for specified beams, filters by sensitivity, RH95,\n",
        "    and optionally by solar elevation (nighttime), and saves all shots to a CSV.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_list_txt : str\n",
        "        Path to a text file containing one HTTPS URL per line.\n",
        "    csv_file : str\n",
        "        Output CSV file path.\n",
        "    beams : list, optional\n",
        "        List of beam names to extract. Defaults to the four full-power beams.\n",
        "    min_sensitivity : float, optional\n",
        "        Minimum acceptable sensitivity (default: 0.95)\n",
        "    min_rh95 : float, optional\n",
        "        Minimum acceptable RH95 value (default: 0)\n",
        "    night : bool, optional\n",
        "        If True, select only shots where solar_elevation < 0 (nighttime)\n",
        "    \"\"\"\n",
        "    if beams is None:\n",
        "        beams = ['BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
        "\n",
        "    # Read list of URLs\n",
        "    with open(file_list_txt, 'r') as f:\n",
        "        h5_urls = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for url in h5_urls:\n",
        "        print(f\"\\nðŸ“¥ Downloading {url} ...\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=300)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".h5\", delete=False) as tmp:\n",
        "                tmp.write(response.content)\n",
        "                tmp_path = tmp.name\n",
        "\n",
        "            with h5py.File(tmp_path, 'r') as f:\n",
        "                for beam_name in beams:\n",
        "                    if beam_name not in f:\n",
        "                        print(f\"  âš ï¸ Beam {beam_name} not found in {url}\")\n",
        "                        continue\n",
        "\n",
        "                    beam = f[beam_name]\n",
        "\n",
        "                    # Check datasets required for GEDI L2A v2.1+\n",
        "                    required = ['lat_lowestmode', 'lon_lowestmode', 'rh', 'shot_number', 'solar_elevation']\n",
        "                    if not all(k in beam for k in required):\n",
        "                        print(f\"  âš ï¸ Missing required datasets in {beam_name}\")\n",
        "                        continue\n",
        "\n",
        "                    # Try to access sensitivity safely\n",
        "                    sensitivity = None\n",
        "                    if 'QA' in beam and 'sensitivity' in beam['QA']:\n",
        "                        sensitivity = beam['QA/sensitivity'][:]\n",
        "                    elif 'sensitivity' in beam:\n",
        "                        sensitivity = beam['sensitivity'][:]\n",
        "                    else:\n",
        "                        print(f\"  âš ï¸ Sensitivity missing in {beam_name}, skipping beam\")\n",
        "                        continue\n",
        "\n",
        "                    lat = beam['lat_lowestmode'][:]\n",
        "                    lon = beam['lon_lowestmode'][:]\n",
        "                    shot_num = beam['shot_number'][:]\n",
        "                    rh = beam['rh'][:]\n",
        "                    solar = beam['solar_elevation'][:]\n",
        "\n",
        "                    # Extract selected RH metrics\n",
        "                    rh25 = rh[:, 25]\n",
        "                    rh50 = rh[:, 50]\n",
        "                    rh75 = rh[:, 75]\n",
        "                    rh95 = rh[:, 95]\n",
        "\n",
        "                    # Apply filters\n",
        "                    mask = (sensitivity >= min_sensitivity) & (rh95 >= min_rh95)\n",
        "                    if night:\n",
        "                        mask &= (solar < 0)\n",
        "\n",
        "                    if not mask.any():\n",
        "                        print(f\"  âš™ï¸ No shots passed filters in {beam_name}\")\n",
        "                        continue\n",
        "\n",
        "                    df = pd.DataFrame({\n",
        "                        \"source_url\": url,\n",
        "                        \"beam\": beam_name,\n",
        "                        \"shot_number\": shot_num[mask],\n",
        "                        \"latitude\": lat[mask],\n",
        "                        \"longitude\": lon[mask],\n",
        "                        \"rh25\": rh25[mask],\n",
        "                        \"rh50\": rh50[mask],\n",
        "                        \"rh75\": rh75[mask],\n",
        "                        \"rh95\": rh95[mask],\n",
        "                        \"sensitivity\": sensitivity[mask],\n",
        "                        \"solar_elevation\": solar[mask]\n",
        "                    })\n",
        "\n",
        "                    records.append(df)\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"âŒ Download failed for {url}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing {url}: {e}\")\n",
        "        finally:\n",
        "            if 'tmp_path' in locals() and os.path.exists(tmp_path):\n",
        "                os.remove(tmp_path)\n",
        "\n",
        "    # Combine all dataframes\n",
        "    if records:\n",
        "        shots_df = pd.concat(records, ignore_index=True)\n",
        "        shots_df.to_csv(csv_file, index=False)\n",
        "        print(f\"\\nâœ… Total shots saved: {len(shots_df):,}\")\n",
        "        print(f\"âœ… Output file: {csv_file}\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸ No valid shots extracted.\")\n"
      ],
      "metadata": {
        "id": "VgDJmjGG7DRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9- Run the filter function\n",
        "Results will be saved in a CSV file that can be downloaded into your computer"
      ],
      "metadata": {
        "id": "AHNZT9WDV6sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the list of GEDI L2A granules (H5 files) generated by the Harmony subset step\n",
        "gedi_file = os.path.join(output_folder, h5_file_name)\n",
        "\n",
        "out_csv_file_nm = \"gedi_shots_aoi.csv\"\n",
        "out_csv_file = os.path.join(output_folder, out_csv_file_nm)\n",
        "\n",
        "#List of Full Power Beams\n",
        "full_power_beams = ['BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
        "\n",
        "#Get the filtering variables\n",
        "min_sens_input = float(min_sens_input)\n",
        "min_height_input = int(min_height_input)\n",
        "night_only = bool(night_only)\n",
        "\n",
        "#Run the function to filter H5 file and extract RH metrics\n",
        "extract_gedi_rh_metrics_from_urls(gedi_file, out_csv_file, beams=full_power_beams,\n",
        "                                      min_sensitivity=min_sens_input, min_rh95=min_height_input,\n",
        "                                      night=night_only)\n"
      ],
      "metadata": {
        "id": "30bDx6HllyY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}